{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Fatoni Murfid\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Fatoni Murfid S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6545307443365695\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Memuat dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/ghazafm/SocialMediaSentiment/main/preprocessing/Training/data/clean/gabungan.csv')\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'no_alay' contains the text\n",
    "data['no_alay'].apply(lambda x: pos_tag(word_tokenize(x)))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(data['no_alay'])\n",
    "y = data['label']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "# # Membersihkan data dari nilai yang hilang\n",
    "# data_clean = data_gabungan.dropna(subset=['no_stopwords'])\n",
    "\n",
    "# # Membagi data yang telah dibersihkan menjadi set pelatihan dan pengujian\n",
    "# X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(\n",
    "#     data_clean['no_stopwords'], data_clean['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# # Mengubah teks ke representasi numerik dengan TF-IDF pada data yang telah dibersihkan\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_train_tfidf_clean = tfidf_vectorizer.fit_transform(X_train_clean)\n",
    "# X_test_tfidf_clean = tfidf_vectorizer.transform(X_test_clean)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Mendefinisikan dan melatih model Random Forest pada data yang telah dibersihkan\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf_model.fit(X_train_tfidf_clean, y_train_clean)\n",
    "\n",
    "# # Membuat prediksi pada set pengujian yang telah dibersihkan dengan Random Forest\n",
    "# y_pred_rf = rf_model.predict(X_test_tfidf_clean)\n",
    "\n",
    "# # Mengevaluasi performa model Random Forest pada data yang telah dibersihkan\n",
    "# accuracy_rf = accuracy_score(y_test_clean, y_pred_rf)\n",
    "# classification_report_results_rf = classification_report(y_test_clean, y_pred_rf)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy_rf}\")\n",
    "# print(classification_report_results_rf)\n",
    "\n",
    "# # # Mendefinisikan dan melatih model Naive Bayes pada data yang telah dibersihkan\n",
    "# # nb_model_clean = MultinomialNB()\n",
    "# # nb_model_clean.fit(X_train_tfidf_clean, y_train_clean)\n",
    "\n",
    "# # # Membuat prediksi pada set pengujian yang telah dibersihkan\n",
    "# # y_pred_clean = nb_model_clean.predict(X_test_tfidf_clean)\n",
    "\n",
    "# # # Mengevaluasi performa model pada data yang telah dibersihkan\n",
    "# # accuracy_clean = accuracy_score(y_test_clean, y_pred_clean)\n",
    "# # classification_report_results_clean = classification_report(y_test_clean, y_pred_clean)\n",
    "\n",
    "# # print(f\"Accuracy: {accuracy_clean}\")\n",
    "# # print(classification_report_results_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contoh = ['adapun hal itu disampaikan hashim dalam sambutannya pada acara yang diselenggarakan prabowo mania deklarasikan prabowo subianto presiden di museum joang jakarta minggu',\n",
    "'presiden indonesia tahun kata dia harus prabowo subianto',\n",
    "'pasti dan pedofilia akan diberantas prabowo presiden',\n",
    "'dukungan terhadap prabowo subianto untuk maju sebagai calon presiden pada pemilu datang dari sulawesi utaracapres pemilu dekade terusmajubersamaprabowo mendingprabowo mendingprabowo',\n",
    "'pemerintah gak becus',\n",
    "'pemerintah becus',\n",
    "'prabowo ga gemoy'\n",
    "\n",
    "]\n",
    "contoh = vectorizer.transform(contoh)\n",
    "prediksi = random_forest.predict(contoh)\n",
    "print(prediksi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
