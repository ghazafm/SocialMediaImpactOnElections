{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ghazafm/SocialMediaSentiment/main/preprocessing/Training/data/clean/pos_tagging/gabungan.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>no_alay</th>\n",
       "      <th>pos</th>\n",
       "      <th>clean_manual</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info  anies presiden</td>\n",
       "      <td>Positive</td>\n",
       "      <td>info anies presiden</td>\n",
       "      <td>[('info', 'NN'), ('anies', 'NN'), ('presiden',...</td>\n",
       "      <td>info NN</td>\n",
       "      <td>info NN</td>\n",
       "      <td>info NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politisi partai gerindra sandiaga uno menjawab...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>politisi partai gerindra sandiaga uno menjawab...</td>\n",
       "      <td>[('politisi', 'NN'), ('partai', 'NN'), ('gerin...</td>\n",
       "      <td>politisi NN menjawab VB soal NN diduetkan VB k...</td>\n",
       "      <td>politis NN jawab VB soal NN duet VB kembali VB...</td>\n",
       "      <td>politis NN jawab VB soal NN duet VB mantan JJ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lanjut pak anies kita kawal sampai jadi presiden</td>\n",
       "      <td>Positive</td>\n",
       "      <td>lanjut pak anies kita kawal sampai jadi presiden</td>\n",
       "      <td>[('lanjut', 'VB'), ('pak', 'NN'), ('anies', 'N...</td>\n",
       "      <td>lanjut VB pak NN kita PRP kawal NN sampai SC</td>\n",
       "      <td>lanjut VB pak NN kita PRP kawal NN sampai SC</td>\n",
       "      <td>lanjut VB pak NN kawal NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semoga allah swt menyelamatkan bangsa dan nega...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>semoga allah swt menyelamatkan bangsa dan nega...</td>\n",
       "      <td>[('semoga', 'SC'), ('allah', 'VB'), ('swt', 'N...</td>\n",
       "      <td>swt NN menyelamatkan VB bangsa NN dan CC negar...</td>\n",
       "      <td>swt NN selamat VB bangsa NN dan CC negara NN r...</td>\n",
       "      <td>swt NN selamat VB bangsa NN negara NN republik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chotimah kasian ya pa anies makanya sudah teka...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>chotimah kasihan ya apa anies makanya sudah te...</td>\n",
       "      <td>[('chotimah', 'NN'), ('kasihan', 'NN'), ('ya',...</td>\n",
       "      <td>kasihan NN ya NN makanya RB sudah MD tekad VB ...</td>\n",
       "      <td>kasihan NN ya NN makanya RB sudah MD tekad VB ...</td>\n",
       "      <td>kasihan NN makanya RB tekad VB keluarga NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24317</th>\n",
       "      <td>pa ganjar pranowo nex presiden indonesia</td>\n",
       "      <td>Negative</td>\n",
       "      <td>apa ganjar pranowo nex presiden indonesia</td>\n",
       "      <td>[('apa', 'WH'), ('ganjar', 'FW'), ('pranowo', ...</td>\n",
       "      <td>nex FW</td>\n",
       "      <td>nex FW</td>\n",
       "      <td>nex FW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24318</th>\n",
       "      <td>rt ganjaristdltras ganjarist deltras jatim sia...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>rt ganjaristdltras ganjarist deltras jatim sia...</td>\n",
       "      <td>[('rt', 'FW'), ('ganjaristdltras', 'FW'), ('ga...</td>\n",
       "      <td>rt FW ganjaristdltras FW ganjarist FW deltras ...</td>\n",
       "      <td>rt FW ganjaristdltras FW ganjarist FW deltras ...</td>\n",
       "      <td>rt FW ganjaristdltras FW ganjarist FW deltras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24319</th>\n",
       "      <td>artinya ganjar pranowo presiden</td>\n",
       "      <td>Negative</td>\n",
       "      <td>artinya ganjar pranowo presiden</td>\n",
       "      <td>[('artinya', 'RB'), ('ganjar', 'VB'), ('pranow...</td>\n",
       "      <td>artinya RB</td>\n",
       "      <td>arti RB</td>\n",
       "      <td>arti RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24320</th>\n",
       "      <td>semakin banyak rakyat yang siap mendukung ganj...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>semakin banyak rakyat yang siap mendukung ganj...</td>\n",
       "      <td>[('semakin', 'RB'), ('banyak', 'CD'), ('rakyat...</td>\n",
       "      <td>semakin RB yang SC siap VB untuk SC sebagai IN...</td>\n",
       "      <td>makin RB yang SC siap VB untuk SC bagai IN ke ...</td>\n",
       "      <td>makin RB siap VB bagai IN selamat JJ ulang VB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24321</th>\n",
       "      <td>selamat hari penerbangan nasional oktober terb...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>selamat hari penerbangan nasional oktober terb...</td>\n",
       "      <td>[('selamat', 'NN'), ('hari', 'NN'), ('penerban...</td>\n",
       "      <td>selamat NN penerbangan NN nasional JJ oktober ...</td>\n",
       "      <td>selamat NN terbang NN nasional JJ oktober NN t...</td>\n",
       "      <td>selamat NN terbang NN nasional JJ oktober NN t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24322 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet     label  \\\n",
       "0                                   info  anies presiden  Positive   \n",
       "1      politisi partai gerindra sandiaga uno menjawab...  Positive   \n",
       "2       lanjut pak anies kita kawal sampai jadi presiden  Positive   \n",
       "3      semoga allah swt menyelamatkan bangsa dan nega...  Positive   \n",
       "4      chotimah kasian ya pa anies makanya sudah teka...  Positive   \n",
       "...                                                  ...       ...   \n",
       "24317           pa ganjar pranowo nex presiden indonesia  Negative   \n",
       "24318  rt ganjaristdltras ganjarist deltras jatim sia...  Negative   \n",
       "24319                    artinya ganjar pranowo presiden  Negative   \n",
       "24320  semakin banyak rakyat yang siap mendukung ganj...  Negative   \n",
       "24321  selamat hari penerbangan nasional oktober terb...  Negative   \n",
       "\n",
       "                                                 no_alay  \\\n",
       "0                                    info anies presiden   \n",
       "1      politisi partai gerindra sandiaga uno menjawab...   \n",
       "2       lanjut pak anies kita kawal sampai jadi presiden   \n",
       "3      semoga allah swt menyelamatkan bangsa dan nega...   \n",
       "4      chotimah kasihan ya apa anies makanya sudah te...   \n",
       "...                                                  ...   \n",
       "24317          apa ganjar pranowo nex presiden indonesia   \n",
       "24318  rt ganjaristdltras ganjarist deltras jatim sia...   \n",
       "24319                    artinya ganjar pranowo presiden   \n",
       "24320  semakin banyak rakyat yang siap mendukung ganj...   \n",
       "24321  selamat hari penerbangan nasional oktober terb...   \n",
       "\n",
       "                                                     pos  \\\n",
       "0      [('info', 'NN'), ('anies', 'NN'), ('presiden',...   \n",
       "1      [('politisi', 'NN'), ('partai', 'NN'), ('gerin...   \n",
       "2      [('lanjut', 'VB'), ('pak', 'NN'), ('anies', 'N...   \n",
       "3      [('semoga', 'SC'), ('allah', 'VB'), ('swt', 'N...   \n",
       "4      [('chotimah', 'NN'), ('kasihan', 'NN'), ('ya',...   \n",
       "...                                                  ...   \n",
       "24317  [('apa', 'WH'), ('ganjar', 'FW'), ('pranowo', ...   \n",
       "24318  [('rt', 'FW'), ('ganjaristdltras', 'FW'), ('ga...   \n",
       "24319  [('artinya', 'RB'), ('ganjar', 'VB'), ('pranow...   \n",
       "24320  [('semakin', 'RB'), ('banyak', 'CD'), ('rakyat...   \n",
       "24321  [('selamat', 'NN'), ('hari', 'NN'), ('penerban...   \n",
       "\n",
       "                                            clean_manual  \\\n",
       "0                                                info NN   \n",
       "1      politisi NN menjawab VB soal NN diduetkan VB k...   \n",
       "2           lanjut VB pak NN kita PRP kawal NN sampai SC   \n",
       "3      swt NN menyelamatkan VB bangsa NN dan CC negar...   \n",
       "4      kasihan NN ya NN makanya RB sudah MD tekad VB ...   \n",
       "...                                                  ...   \n",
       "24317                                             nex FW   \n",
       "24318  rt FW ganjaristdltras FW ganjarist FW deltras ...   \n",
       "24319                                         artinya RB   \n",
       "24320  semakin RB yang SC siap VB untuk SC sebagai IN...   \n",
       "24321  selamat NN penerbangan NN nasional JJ oktober ...   \n",
       "\n",
       "                                                 stemmed  \\\n",
       "0                                                info NN   \n",
       "1      politis NN jawab VB soal NN duet VB kembali VB...   \n",
       "2           lanjut VB pak NN kita PRP kawal NN sampai SC   \n",
       "3      swt NN selamat VB bangsa NN dan CC negara NN r...   \n",
       "4      kasihan NN ya NN makanya RB sudah MD tekad VB ...   \n",
       "...                                                  ...   \n",
       "24317                                             nex FW   \n",
       "24318  rt FW ganjaristdltras FW ganjarist FW deltras ...   \n",
       "24319                                            arti RB   \n",
       "24320  makin RB yang SC siap VB untuk SC bagai IN ke ...   \n",
       "24321  selamat NN terbang NN nasional JJ oktober NN t...   \n",
       "\n",
       "                                            no_stopwords  \n",
       "0                                                info NN  \n",
       "1      politis NN jawab VB soal NN duet VB mantan JJ ...  \n",
       "2                              lanjut VB pak NN kawal NN  \n",
       "3      swt NN selamat VB bangsa NN negara NN republik...  \n",
       "4             kasihan NN makanya RB tekad VB keluarga NN  \n",
       "...                                                  ...  \n",
       "24317                                             nex FW  \n",
       "24318  rt FW ganjaristdltras FW ganjarist FW deltras ...  \n",
       "24319                                            arti RB  \n",
       "24320  makin RB siap VB bagai IN selamat JJ ulang VB ...  \n",
       "24321  selamat NN terbang NN nasional JJ oktober NN t...  \n",
       "\n",
       "[24322 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder\n",
    "def label_encoder(y):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    return y\n",
    "\n",
    "# under dan over sampling\n",
    "def undersampling(x, y):\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rus = RandomUnderSampler()\n",
    "    x, y = rus.fit_resample(x.values.reshape(-1,1),y)\n",
    "    x = x.flatten()\n",
    "    return x, y\n",
    "\n",
    "def oversampling(x, y):\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    ros = RandomOverSampler()\n",
    "    x, y = ros.fit_resample(x.values.reshape(-1,1),y)\n",
    "    x = x.flatten()\n",
    "    return x, y\n",
    "\n",
    "# train test split\n",
    "def bagi_data(x, y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=2)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# cetak csv\n",
    "def cetak_csv(data):\n",
    "    data.to_csv('name.csv')\n",
    "\n",
    "# Vectorizing\n",
    "def tfidf_vec(x_train, x_test):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    x_train = vectorizer.fit_transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    return x_train, x_test\n",
    "\n",
    "def count_vec(x_train, x_test):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    x_train = vectorizer.fit_transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    return x_train, x_test\n",
    "\n",
    "# Metric Scorer\n",
    "def accuracy_score(y_test, y_pred):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def f1_score_pos(x,y):\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1 = f1_score(x,y,pos_label='Positive')\n",
    "    return f1\n",
    "def f1_score_neg(x,y):\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1 = f1_score(x,y,pos_label='Negative')\n",
    "    return f1\n",
    "\n",
    "def precission_pos(x,y):\n",
    "    from sklearn.metrics import precision_score\n",
    "    precision = precision_score(x,y,pos_label='Positive')\n",
    "    return precision\n",
    "def precission_neg(x,y):\n",
    "    from sklearn.metrics import precision_score\n",
    "    precision = precision_score(x,y,pos_label='Negative')\n",
    "    return precision\n",
    "\n",
    "def recall_pos(x,y):\n",
    "    from sklearn.metrics import recall_score\n",
    "    recall = recall_score(x,y,'Positive')\n",
    "    return recall\n",
    "def recall_neg(x,y):\n",
    "    from sklearn.metrics import recall_score\n",
    "    recall = recall_score(x,y,'Negative')\n",
    "    return recall\n",
    "\n",
    "def all_report (x,y):\n",
    "    from sklearn.metrics import classification_report\n",
    "    report = classification_report(x,y)\n",
    "    return report\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting & under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Negative    8752\n",
       "Positive    8752\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['no_stopwords']\n",
    "y = df['label']\n",
    "\n",
    "x, y = undersampling(x, y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = bagi_data(x, y)\n",
    "\n",
    "y.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-idf vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = tfidf_vec(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.469 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.455 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.470 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.462 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.452 total time=   0.0s\n",
      "[CV 1/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.559 total time=   0.1s\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.552 total time=   0.1s\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.544 total time=   0.1s\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.551 total time=   0.1s\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.578 total time=   0.0s\n",
      "[CV 1/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.586 total time=   0.1s\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.575 total time=   0.1s\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.575 total time=   0.2s\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.566 total time=   0.1s\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.591 total time=   0.3s\n",
      "[CV 1/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, penalty=l2;, score=0.574 total time=   0.5s\n",
      "[CV 2/5] END ...................C=1, penalty=l2;, score=0.569 total time=   0.3s\n",
      "[CV 3/5] END ...................C=1, penalty=l2;, score=0.586 total time=   0.4s\n",
      "[CV 4/5] END ...................C=1, penalty=l2;, score=0.572 total time=   0.4s\n",
      "[CV 5/5] END ...................C=1, penalty=l2;, score=0.595 total time=   0.6s\n",
      "[CV 1/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..................C=10, penalty=l2;, score=0.567 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..................C=10, penalty=l2;, score=0.555 total time=   1.3s\n",
      "[CV 3/5] END ..................C=10, penalty=l2;, score=0.579 total time=   1.1s\n",
      "[CV 4/5] END ..................C=10, penalty=l2;, score=0.557 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..................C=10, penalty=l2;, score=0.574 total time=   1.3s\n",
      "[CV 1/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .................C=100, penalty=l2;, score=0.560 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .................C=100, penalty=l2;, score=0.542 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .................C=100, penalty=l2;, score=0.553 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .................C=100, penalty=l2;, score=0.554 total time=   1.5s\n",
      "[CV 5/5] END .................C=100, penalty=l2;, score=0.562 total time=   1.3s\n",
      "[CV 1/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "{'C': 1, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "90 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.46143015        nan        nan        nan 0.55670123\n",
      "        nan        nan        nan 0.57853641        nan        nan\n",
      "        nan 0.57933297        nan        nan        nan 0.56617116\n",
      "        nan        nan        nan 0.55449844        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(random_state=42)\n",
    "\n",
    "parameter = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# from sklearn.metrics import recall_score, make_scorer\n",
    "\n",
    "# # Membuat scorer untuk recall positif\n",
    "# scorer = make_scorer(recall_score, pos_label='Positive')\n",
    "\n",
    "# from sklearn.metrics import precision_score, make_scorer\n",
    "\n",
    "# # Membuat scorer untuk precision\n",
    "# precision_score = make_scorer(precision_score, pos_label='Positive')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "GS = GridSearchCV(estimator = logistic,\n",
    "                    param_grid = parameter,\n",
    "                    scoring = 'f1_macro', \n",
    "                    refit = False,\n",
    "                    cv=5,\n",
    "                    verbose = 3)\n",
    "\n",
    "GS.fit(x_train, y_train)\n",
    "print(GS.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(random_state=42, C=1, penalty='l2')\n",
    "logistic.fit(x_train, y_train)\n",
    "    \n",
    "y_pred = logistic.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Logistic Regression with tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.58      0.58      0.58      1725\n",
      "    Positive       0.59      0.60      0.60      1776\n",
      "\n",
      "    accuracy                           0.59      3501\n",
      "   macro avg       0.59      0.59      0.59      3501\n",
      "weighted avg       0.59      0.59      0.59      3501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'LogisticRegression_Tag.pkl'\n",
    "pickle.dump(logistic, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# f1 = f1_score(y_test, y_pred, pos_label='Negative')\n",
    "\n",
    "# # Mencetak hasil\n",
    "# print(\"F1 Score:\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
