{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ghazafm/SocialMediaSentiment/main/preprocessing/Training/data/clean/regular/gabungan.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>no_alay</th>\n",
       "      <th>clean_manual</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info  anies presiden</td>\n",
       "      <td>Positive</td>\n",
       "      <td>info anies presiden</td>\n",
       "      <td>info</td>\n",
       "      <td>info</td>\n",
       "      <td>info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politisi partai gerindra sandiaga uno menjawab...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>politisi partai gerindra sandiaga uno menjawab...</td>\n",
       "      <td>politisi menjawab soal diduetkan kembali denga...</td>\n",
       "      <td>politis jawab soal duet kembali dengan mantan ...</td>\n",
       "      <td>politis jawab soal duet dengan mantan dki jaka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lanjut pak anies kita kawal sampai jadi presiden</td>\n",
       "      <td>Positive</td>\n",
       "      <td>lanjut pak anies kita kawal sampai jadi presiden</td>\n",
       "      <td>lanjut pak kita kawal sampai</td>\n",
       "      <td>lanjut pak kita kawal sampai</td>\n",
       "      <td>lanjut pak kawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semoga allah swt menyelamatkan bangsa dan nega...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>semoga allah swt menyelamatkan bangsa dan nega...</td>\n",
       "      <td>swt menyelamatkan bangsa dan negara republik d...</td>\n",
       "      <td>swt selamat bangsa dan negara republik dari pa...</td>\n",
       "      <td>swt selamat bangsa negara republik para penghi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chotimah kasian ya pa anies makanya sudah teka...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>chotimah kasihan ya apa anies makanya sudah te...</td>\n",
       "      <td>kasihan ya makanya sudah tekad keluarga saya</td>\n",
       "      <td>kasihan ya makanya sudah tekad keluarga saya</td>\n",
       "      <td>kasihan makanya tekad keluarga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24713</th>\n",
       "      <td>pa ganjar pranowo nex presiden indonesia</td>\n",
       "      <td>Negative</td>\n",
       "      <td>apa ganjar pranowo nex presiden indonesia</td>\n",
       "      <td>nex</td>\n",
       "      <td>nex</td>\n",
       "      <td>nex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24714</th>\n",
       "      <td>rt ganjaristdltras ganjarist deltras jatim sia...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>rt ganjaristdltras ganjarist deltras jatim sia...</td>\n",
       "      <td>rt ganjaristdltras ganjarist deltras jatim siap</td>\n",
       "      <td>rt ganjaristdltras ganjarist deltras jatim siap</td>\n",
       "      <td>rt ganjaristdltras ganjarist deltras jatim siap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24715</th>\n",
       "      <td>artinya ganjar pranowo presiden</td>\n",
       "      <td>Negative</td>\n",
       "      <td>artinya ganjar pranowo presiden</td>\n",
       "      <td>artinya</td>\n",
       "      <td>arti</td>\n",
       "      <td>arti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24716</th>\n",
       "      <td>semakin banyak rakyat yang siap mendukung ganj...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>semakin banyak rakyat yang siap mendukung ganj...</td>\n",
       "      <td>semakin yang siap untuk sebagai ke selamat ula...</td>\n",
       "      <td>makin yang siap untuk bagai ke selamat ulang p...</td>\n",
       "      <td>makin siap bagai selamat ulang pak tuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24717</th>\n",
       "      <td>selamat hari penerbangan nasional oktober terb...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>selamat hari penerbangan nasional oktober terb...</td>\n",
       "      <td>selamat penerbangan nasional oktober terbangla...</td>\n",
       "      <td>selamat terbang nasional oktober terbang tingg...</td>\n",
       "      <td>selamat terbang nasional oktober terbang tingg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24384 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet     label  \\\n",
       "0                                   info  anies presiden  Positive   \n",
       "1      politisi partai gerindra sandiaga uno menjawab...  Positive   \n",
       "2       lanjut pak anies kita kawal sampai jadi presiden  Positive   \n",
       "3      semoga allah swt menyelamatkan bangsa dan nega...  Positive   \n",
       "4      chotimah kasian ya pa anies makanya sudah teka...  Positive   \n",
       "...                                                  ...       ...   \n",
       "24713           pa ganjar pranowo nex presiden indonesia  Negative   \n",
       "24714  rt ganjaristdltras ganjarist deltras jatim sia...  Negative   \n",
       "24715                    artinya ganjar pranowo presiden  Negative   \n",
       "24716  semakin banyak rakyat yang siap mendukung ganj...  Negative   \n",
       "24717  selamat hari penerbangan nasional oktober terb...  Negative   \n",
       "\n",
       "                                                 no_alay  \\\n",
       "0                                    info anies presiden   \n",
       "1      politisi partai gerindra sandiaga uno menjawab...   \n",
       "2       lanjut pak anies kita kawal sampai jadi presiden   \n",
       "3      semoga allah swt menyelamatkan bangsa dan nega...   \n",
       "4      chotimah kasihan ya apa anies makanya sudah te...   \n",
       "...                                                  ...   \n",
       "24713          apa ganjar pranowo nex presiden indonesia   \n",
       "24714  rt ganjaristdltras ganjarist deltras jatim sia...   \n",
       "24715                    artinya ganjar pranowo presiden   \n",
       "24716  semakin banyak rakyat yang siap mendukung ganj...   \n",
       "24717  selamat hari penerbangan nasional oktober terb...   \n",
       "\n",
       "                                            clean_manual  \\\n",
       "0                                                   info   \n",
       "1      politisi menjawab soal diduetkan kembali denga...   \n",
       "2                           lanjut pak kita kawal sampai   \n",
       "3      swt menyelamatkan bangsa dan negara republik d...   \n",
       "4           kasihan ya makanya sudah tekad keluarga saya   \n",
       "...                                                  ...   \n",
       "24713                                                nex   \n",
       "24714    rt ganjaristdltras ganjarist deltras jatim siap   \n",
       "24715                                            artinya   \n",
       "24716  semakin yang siap untuk sebagai ke selamat ula...   \n",
       "24717  selamat penerbangan nasional oktober terbangla...   \n",
       "\n",
       "                                                 stemmed  \\\n",
       "0                                                   info   \n",
       "1      politis jawab soal duet kembali dengan mantan ...   \n",
       "2                           lanjut pak kita kawal sampai   \n",
       "3      swt selamat bangsa dan negara republik dari pa...   \n",
       "4           kasihan ya makanya sudah tekad keluarga saya   \n",
       "...                                                  ...   \n",
       "24713                                                nex   \n",
       "24714    rt ganjaristdltras ganjarist deltras jatim siap   \n",
       "24715                                               arti   \n",
       "24716  makin yang siap untuk bagai ke selamat ulang p...   \n",
       "24717  selamat terbang nasional oktober terbang tingg...   \n",
       "\n",
       "                                            no_stopwords  \n",
       "0                                                   info  \n",
       "1      politis jawab soal duet dengan mantan dki jaka...  \n",
       "2                                       lanjut pak kawal  \n",
       "3      swt selamat bangsa negara republik para penghi...  \n",
       "4                         kasihan makanya tekad keluarga  \n",
       "...                                                  ...  \n",
       "24713                                                nex  \n",
       "24714    rt ganjaristdltras ganjarist deltras jatim siap  \n",
       "24715                                               arti  \n",
       "24716           makin siap bagai selamat ulang pak tuhan  \n",
       "24717  selamat terbang nasional oktober terbang tingg...  \n",
       "\n",
       "[24384 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder\n",
    "def label_encoder(y):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    return y\n",
    "\n",
    "# under dan over sampling\n",
    "def undersampling(x, y):\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rus = RandomUnderSampler()\n",
    "    x, y = rus.fit_resample(x.values.reshape(-1,1),y)\n",
    "    x = x.flatten()\n",
    "    return x, y\n",
    "\n",
    "def oversampling(x, y):\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    ros = RandomOverSampler()\n",
    "    x, y = ros.fit_resample(x.values.reshape(-1,1),y)\n",
    "    x = x.flatten()\n",
    "    return x, y\n",
    "\n",
    "# train test split\n",
    "def bagi_data(x, y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=2)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# cetak csv\n",
    "def cetak_csv(data):\n",
    "    data.to_csv('name.csv')\n",
    "\n",
    "# Vectorizing\n",
    "def tfidf_vec(x_train, x_test):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    x_train = vectorizer.fit_transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    return x_train, x_test\n",
    "\n",
    "def count_vec(x_train, x_test):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    x_train = vectorizer.fit_transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    return x_train, x_test\n",
    "\n",
    "# Metric Scorer\n",
    "def accuracy_score(y_test, y_pred):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def f1_score_pos(x,y):\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1 = f1_score(x,y,pos_label='Positive')\n",
    "    return f1\n",
    "def f1_score_neg(x,y):\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1 = f1_score(x,y,pos_label='Negative')\n",
    "    return f1\n",
    "\n",
    "def precission_pos(x,y):\n",
    "    from sklearn.metrics import precision_score\n",
    "    precision = precision_score(x,y,pos_label='Positive')\n",
    "    return precision\n",
    "def precission_neg(x,y):\n",
    "    from sklearn.metrics import precision_score\n",
    "    precision = precision_score(x,y,pos_label='Negative')\n",
    "    return precision\n",
    "\n",
    "def recall_pos(x,y):\n",
    "    from sklearn.metrics import recall_score\n",
    "    recall = recall_score(x,y,'Positive')\n",
    "    return recall\n",
    "def recall_neg(x,y):\n",
    "    from sklearn.metrics import recall_score\n",
    "    recall = recall_score(x,y,'Negative')\n",
    "    return recall\n",
    "\n",
    "def all_report (x,y):\n",
    "    from sklearn.metrics import classification_report\n",
    "    report = classification_report(x,y)\n",
    "    return report\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting & under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Negative    8770\n",
       "Positive    8770\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['no_stopwords']\n",
    "y = df['label']\n",
    "\n",
    "x, y = undersampling(x, y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = bagi_data(x, y)\n",
    "\n",
    "y.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-idf vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = tfidf_vec(x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................C=0.001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.357 total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.351 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.352 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.347 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.352 total time=   0.0s\n",
      "[CV 1/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .........C=0.001, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.001, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.553 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.553 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.552 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.563 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.573 total time=   0.0s\n",
      "[CV 1/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................C=0.01, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.587 total time=   0.0s\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.576 total time=   0.0s\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.585 total time=   0.1s\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.574 total time=   0.0s\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.589 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................C=0.1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, penalty=l2;, score=0.583 total time=   0.2s\n",
      "[CV 2/5] END ...................C=1, penalty=l2;, score=0.568 total time=   0.1s\n",
      "[CV 3/5] END ...................C=1, penalty=l2;, score=0.588 total time=   0.2s\n",
      "[CV 4/5] END ...................C=1, penalty=l2;, score=0.585 total time=   0.1s\n",
      "[CV 5/5] END ...................C=1, penalty=l2;, score=0.584 total time=   0.1s\n",
      "[CV 1/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .............C=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=1, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, penalty=l2;, score=0.573 total time=   0.5s\n",
      "[CV 2/5] END ..................C=10, penalty=l2;, score=0.561 total time=   0.3s\n",
      "[CV 3/5] END ..................C=10, penalty=l2;, score=0.557 total time=   0.6s\n",
      "[CV 4/5] END ..................C=10, penalty=l2;, score=0.570 total time=   0.3s\n",
      "[CV 5/5] END ..................C=10, penalty=l2;, score=0.577 total time=   0.3s\n",
      "[CV 1/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..................C=10, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=100, penalty=l2;, score=0.555 total time=   0.9s\n",
      "[CV 2/5] END .................C=100, penalty=l2;, score=0.554 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .................C=100, penalty=l2;, score=0.547 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .................C=100, penalty=l2;, score=0.549 total time=   1.3s\n",
      "[CV 5/5] END .................C=100, penalty=l2;, score=0.575 total time=   0.9s\n",
      "[CV 1/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .................C=100, penalty=none;, score=nan total time=   0.0s\n",
      "{'C': 0.1, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "90 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Fatoni Murfid S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.35175428        nan        nan        nan 0.55895708\n",
      "        nan        nan        nan 0.58217066        nan        nan\n",
      "        nan 0.58141966        nan        nan        nan 0.56750058\n",
      "        nan        nan        nan 0.55592731        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(random_state=42)\n",
    "\n",
    "parameter = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# from sklearn.metrics import recall_score, make_scorer\n",
    "\n",
    "# # Membuat scorer untuk recall positif\n",
    "# scorer = make_scorer(recall_score, pos_label='Positive')\n",
    "\n",
    "# from sklearn.metrics import precision_score, make_scorer\n",
    "\n",
    "# # Membuat scorer untuk precision\n",
    "# precision_score = make_scorer(precision_score, pos_label='Positive')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "GS = GridSearchCV(estimator = logistic,\n",
    "                    param_grid = parameter,\n",
    "                    scoring = 'f1_macro', \n",
    "                    refit = False,\n",
    "                    cv=5,\n",
    "                    verbose = 3)\n",
    "\n",
    "GS.fit(x_train, y_train)\n",
    "print(GS.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(random_state=42, C=0.1, penalty='l2')\n",
    "logistic.fit(x_train, y_train)\n",
    "    \n",
    "y_pred = logistic.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Logistic Regression untag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.58      0.64      0.61      1708\n",
      "    Positive       0.62      0.56      0.59      1800\n",
      "\n",
      "    accuracy                           0.60      3508\n",
      "   macro avg       0.60      0.60      0.60      3508\n",
      "weighted avg       0.60      0.60      0.60      3508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'LogisticRegression_Untag.pkl'\n",
    "pickle.dump(logistic, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# f1 = f1_score(y_test, y_pred, pos_label='Negative')\n",
    "\n",
    "# # Mencetak hasil\n",
    "# print(\"F1 Score:\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
