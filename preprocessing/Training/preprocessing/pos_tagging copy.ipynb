{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/xq7119ld627_2wyd6dkmwl0m0000gn/T/ipykernel_69868/2225076835.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk import word_tokenize\n",
    "from nltk.tag import CRFTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anis = pd.read_csv('https://raw.github.com/ghazafm/SocialMediaSentiment/main/preprocessing/Training/data/raw/anis.csv')\n",
    "df_prabowo = pd.read_csv('https://raw.github.com/ghazafm/SocialMediaSentiment/main/preprocessing/Training/data/raw/prabowo.csv')\n",
    "df_ganjar = pd.read_csv('https://raw.github.com/ghazafm/SocialMediaSentiment/main/preprocessing/Training/data/raw/ganjar.csv')\n",
    "\n",
    "df_anis.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df_prabowo.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df_ganjar.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anis.drop_duplicates(inplace=True)\n",
    "df_prabowo.drop_duplicates(inplace=True)\n",
    "df_ganjar.drop_duplicates(inplace=True)\n",
    "df_anis.dropna(inplace=True)\n",
    "df_prabowo.dropna(inplace=True)\n",
    "df_ganjar.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alay = pd.read_csv('https://raw.githubusercontent.com/nasalsabila/kamus-alay/master/colloquial-indonesian-lexicon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alay = dict(zip(alay['slang'], alay['formal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cek_alay(word, alay):\n",
    "    return alay.get(word, word)\n",
    "\n",
    "\n",
    "def clear_alay(data):\n",
    "    words = str(data)\n",
    "    words = words.split()\n",
    "    cleared_words = [cek_alay(word, alay) for word in words]\n",
    "    return ' '.join(cleared_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anis['no_alay'] = df_anis['Tweet'].apply(clear_alay)\n",
    "df_prabowo['no_alay'] = df_prabowo['Tweet'].apply(clear_alay)\n",
    "df_ganjar['no_alay'] = df_ganjar['Tweet'].apply(clear_alay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CRFTagger()\n",
    "ct.set_model_file('all_indo_man_tag_corpus_model.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_anis = df_anis['no_alay'].apply(tokenizer)\n",
    "tokenize_prabowo = df_prabowo['no_alay'].apply(tokenizer)\n",
    "tokenize_ganjar = df_ganjar['no_alay'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anis['pos'] = ct.tag_sents(tokenize_anis)\n",
    "df_prabowo['pos'] = ct.tag_sents(tokenize_prabowo)\n",
    "df_ganjar['pos'] = ct.tag_sents(tokenize_ganjar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>no_alay</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info  anies presiden</td>\n",
       "      <td>Positive</td>\n",
       "      <td>info anies presiden</td>\n",
       "      <td>[(info, NN), (anies, NN), (presiden, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politisi partai gerindra sandiaga uno menjawab...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>politisi partai gerindra sandiaga uno menjawab...</td>\n",
       "      <td>[(politisi, NN), (partai, NN), (gerindra, NN),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lanjut pak anies kita kawal sampai jadi presiden</td>\n",
       "      <td>Positive</td>\n",
       "      <td>lanjut pak anies kita kawal sampai jadi presiden</td>\n",
       "      <td>[(lanjut, VB), (pak, NN), (anies, NN), (kita, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semoga allah swt menyelamatkan bangsa dan nega...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>semoga allah swt menyelamatkan bangsa dan nega...</td>\n",
       "      <td>[(semoga, SC), (allah, VB), (swt, NN), (menyel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chotimah kasian ya pa anies makanya sudah teka...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>chotimah kasihan ya apa anies makanya sudah te...</td>\n",
       "      <td>[(chotimah, NN), (kasihan, NN), (ya, NN), (apa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>tidak ada gejolak sara selama membangun pks pu...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>tidak ada gejolak sara selama membangun pks pu...</td>\n",
       "      <td>[(tidak, NEG), (ada, VB), (gejolak, NN), (sara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>ubedilah mahfud md otak di balik perppu ciptak...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>ubedilah mahfud md otak di balik perppu ciptak...</td>\n",
       "      <td>[(ubedilah, NN), (mahfud, FW), (md, FW), (otak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>my presiden mranies</td>\n",
       "      <td>Negative</td>\n",
       "      <td>my presiden mranies</td>\n",
       "      <td>[(my, FW), (presiden, FW), (mranies, FW)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>pa anies presiden</td>\n",
       "      <td>Negative</td>\n",
       "      <td>apa anies presiden</td>\n",
       "      <td>[(apa, WH), (anies, NN), (presiden, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>siapakah yg anda pilih presiden anies baswedan...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>siapakah yang anda pilih presiden anies baswed...</td>\n",
       "      <td>[(siapakah, NN), (yang, SC), (anda, PRP), (pil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8913 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet     label  \\\n",
       "0                                  info  anies presiden  Positive   \n",
       "1     politisi partai gerindra sandiaga uno menjawab...  Positive   \n",
       "2      lanjut pak anies kita kawal sampai jadi presiden  Positive   \n",
       "3     semoga allah swt menyelamatkan bangsa dan nega...  Positive   \n",
       "4     chotimah kasian ya pa anies makanya sudah teka...  Positive   \n",
       "...                                                 ...       ...   \n",
       "9995  tidak ada gejolak sara selama membangun pks pu...  Negative   \n",
       "9996  ubedilah mahfud md otak di balik perppu ciptak...  Negative   \n",
       "9997                                my presiden mranies  Negative   \n",
       "9998                                  pa anies presiden  Negative   \n",
       "9999  siapakah yg anda pilih presiden anies baswedan...  Negative   \n",
       "\n",
       "                                                no_alay  \\\n",
       "0                                   info anies presiden   \n",
       "1     politisi partai gerindra sandiaga uno menjawab...   \n",
       "2      lanjut pak anies kita kawal sampai jadi presiden   \n",
       "3     semoga allah swt menyelamatkan bangsa dan nega...   \n",
       "4     chotimah kasihan ya apa anies makanya sudah te...   \n",
       "...                                                 ...   \n",
       "9995  tidak ada gejolak sara selama membangun pks pu...   \n",
       "9996  ubedilah mahfud md otak di balik perppu ciptak...   \n",
       "9997                                my presiden mranies   \n",
       "9998                                 apa anies presiden   \n",
       "9999  siapakah yang anda pilih presiden anies baswed...   \n",
       "\n",
       "                                                    pos  \n",
       "0             [(info, NN), (anies, NN), (presiden, NN)]  \n",
       "1     [(politisi, NN), (partai, NN), (gerindra, NN),...  \n",
       "2     [(lanjut, VB), (pak, NN), (anies, NN), (kita, ...  \n",
       "3     [(semoga, SC), (allah, VB), (swt, NN), (menyel...  \n",
       "4     [(chotimah, NN), (kasihan, NN), (ya, NN), (apa...  \n",
       "...                                                 ...  \n",
       "9995  [(tidak, NEG), (ada, VB), (gejolak, NN), (sara...  \n",
       "9996  [(ubedilah, NN), (mahfud, FW), (md, FW), (otak...  \n",
       "9997          [(my, FW), (presiden, FW), (mranies, FW)]  \n",
       "9998           [(apa, WH), (anies, NN), (presiden, NN)]  \n",
       "9999  [(siapakah, NN), (yang, SC), (anda, PRP), (pil...  \n",
       "\n",
       "[8913 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_meaning = [\n",
    "    'jadi', 'menjadi', 'bapak', 'kalau', 'rakyat', 'siapa', \n",
    "    'apa', 'orang', 'bakal', 'sama', 'pasang', 'jelang', 'tahun', 'hari', \n",
    "    'bersama', 'mau', 'tetap', 'buat', 'for', 'bukan', 'semua', \n",
    "    'terus', 'si', 'inilah', 'kan', 'tak', 'banyak', 'meski', 'lebih', 'keputusan', \n",
    "    'final', 'paling', 'hasil', 'umum', 'tepat', 'tersebut', 'total', 'klik', 'capres', \n",
    "    'pilih', 'pemilihan', 'terpilih', 'survei', 'survey', 'pemilu', 'terkait', 'fahnoor', \n",
    "    'nan', 'calon', 'pilpres', 'resmi', 'cocok', 'politik', 'ribuan', 'ratusan', 'nama','maju',\n",
    "    'hut', 'dapat', 'semoga', 'beliau', 'besar', 'makin', 'layak', 'partai', 'mendukung', 'dukung', \n",
    "    'dukungan', 'gubernur', 'masyarakat', 'warga','presiden','ri','inismyname','pilpres','nan','calon','indonesia','survei','survey','pemilu'\n",
    "]\n",
    "\n",
    "name = [\n",
    "    'inismyname', 'indonesia', 'rosiade', 'joko', 'jokowi', 'widodo', 'ridwan', 'kamil', 'rosiade', \n",
    "    'thohir', 'mujani', 'erick', 'saiful', 'chotimah', 'ahy', 'bukan', 'aniesahy', 'ahmad', \n",
    "    'pks', 'pdip', 'jawa', 'puan', 'maharani', 'pan', 'jateng', 'tengah', 'megawati', 'ppp', \n",
    "    'rasyid', 'gerindra', 'nasdem', 'demokrat', 'pkb', 'allah', #maaffff,\n",
    "    'anis', 'anies', 'baswedan', 'prabowo', 'subianto', 'ganjar', 'pranowo','fahnoor', 'amien','sandiaga',\n",
    "    'chotimah', 'uno'\n",
    "]\n",
    "\n",
    "def clean_manual(data,token=False):\n",
    "    temp = []\n",
    "    if token:\n",
    "        for tup in data:\n",
    "            if tup[0] in double_meaning or tup[0] in name:\n",
    "                continue\n",
    "            temp.append(tup)\n",
    "        return temp\n",
    "    else:\n",
    "        for tup in data:\n",
    "            if tup[0] in double_meaning or tup[0] in name:\n",
    "                continue\n",
    "            temp.append(tup[0])\n",
    "            temp.append(tup[1])\n",
    "    temp = ' '.join(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anis['clean_manual'] = df_anis['pos'].apply(clean_manual)\n",
    "df_prabowo['clean_manual'] = df_prabowo['pos'].apply(clean_manual)\n",
    "df_ganjar['clean_manual'] = df_ganjar['pos'].apply(clean_manual)\n",
    "\n",
    "\n",
    "tokenize_anis = df_anis['pos'].apply(clean_manual,token=True)\n",
    "tokenize_prabowo = df_prabowo['pos'].apply(clean_manual,token=True)\n",
    "tokenize_ganjar = df_ganjar['pos'].apply(clean_manual,token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "def stemming(data,token=False):\n",
    "   temp = []\n",
    "   last = ''\n",
    "   for tup in data:\n",
    "      tup_temp = stemmer.stem(tup[0])\n",
    "      don = [tup_temp,tup[1]]\n",
    "      if token:\n",
    "         temp.append(don)\n",
    "         last = temp\n",
    "      else:\n",
    "         temp.append(' '.join(don))\n",
    "         last = ' '.join(temp)\n",
    "   return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anis['stemmed'] = tokenize_anis.apply(stemming)\n",
    "df_prabowo['stemmed'] = tokenize_prabowo.apply(stemming)\n",
    "df_ganjar['stemmed'] = tokenize_ganjar.apply(stemming)\n",
    "\n",
    "\n",
    "tokenize_anis = tokenize_anis.apply(stemming,token=True)\n",
    "tokenize_prabowo = tokenize_prabowo.apply(stemming,token=True)\n",
    "tokenize_ganjar = tokenize_ganjar.apply(stemming,token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = StopWordRemoverFactory().create_stop_word_remover().dictionary.words\n",
    "\n",
    "def clear_stopwords(data,token=False):\n",
    "    temp = []\n",
    "    last = ''\n",
    "    for tup in data:\n",
    "        if(tup[0] in stopword):\n",
    "            continue\n",
    "        if token:\n",
    "            temp.append(tup)\n",
    "            last = temp\n",
    "        else:\n",
    "            temp.append(' '.join(tup))\n",
    "            last = ' '.join(temp)\n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anis['no_stopwords'] = tokenize_anis.apply(clear_stopwords)\n",
    "df_prabowo['no_stopwords'] = tokenize_prabowo.apply(clear_stopwords)\n",
    "df_ganjar['no_stopwords'] = tokenize_ganjar.apply(clear_stopwords)\n",
    "\n",
    "\n",
    "tokenize_anis = tokenize_anis.apply(clear_stopwords,token=True)\n",
    "tokenize_prabowo = tokenize_prabowo.apply(clear_stopwords,token=True)\n",
    "tokenize_ganjar = tokenize_ganjar.apply(clear_stopwords,token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removena(data):\n",
    "    if len(data) == 0:\n",
    "        return None\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anis['no_stopwords'] = df_anis['no_stopwords'].apply(removena)\n",
    "df_prabowo['no_stopwords'] = df_prabowo['no_stopwords'].apply(removena)\n",
    "df_ganjar['no_stopwords'] = df_ganjar['no_stopwords'].apply(removena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anis.dropna(inplace=True)\n",
    "df_prabowo.dropna(inplace=True)\n",
    "df_ganjar.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = pd.concat([df_anis,df_prabowo,df_ganjar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.path.abspath(os.path.join('..', 'data/clean/pos_tagging'))\n",
    "df_anis.to_csv(f'{dir}/anis.csv',index=False)\n",
    "df_prabowo.to_csv(f'{dir}/prabowo.csv',index=False)\n",
    "df_ganjar.to_csv(f'{dir}/ganjar.csv',index=False)\n",
    "concat.to_csv(f'{dir}/gabungan.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bismillah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
