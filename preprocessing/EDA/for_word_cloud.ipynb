{"cells":[{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import os"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["dir = os.getcwd()\n","df_anis = pd.read_csv('datasets/anis.csv')\n","df_prabowo = pd.read_csv('datasets/prabowo.csv')\n","df_ganjar = pd.read_csv('datasets/ganjar.csv')"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["keyword = [\n","    'inismyname','pilpres','fahnoor','nan','calon','indonesia','survei','survey',\n","    'pemilu','terkait','gerindra','jokowi','capres','pilih','joko','pemilihan','terpilih'\n","]\n","stopwords = [\n","    'di','dan','jadi','yang','dan','pak','sebagai','untuk','ini','akan','menjadi','pada',\n","    'dengan','itu','ke','dari','jika','dalam','nanti','saya','bapak','kami','bisa','kalau',\n","    'rakyat','siapa','apa','ada','orang','kepada','bakal','atau','anda','sama','pasang','jelang',\n","    'sudah','tahun','hari','hanya','juga','tapi','rosiade','hal','kita','saat','adalah','masih',\n","    'bersama','mau','tetap','bahwa','karena','lagi','ingin','buat','kembali', 'for','bukan','semua',\n","    'terhadap','terus','dia','si','inilah','saja','kan','tak'\n","]\n","double_makna = [\n","    'maju',\n","    'hut',\n","    'dapat',\n","    'semoga',\n","    'beliau',\n","    'besar',\n","    'makin',\n","    'layak',\n","    'partai'\n","]\n","nama = [\n","    'widodo',\n","    'ridwan',\n","    'kamil',\n","    'rosiade',\n","    'thohir',\n","    'mujani',\n","    'erick',\n","    'saiful',\n","    'chotimah',\n","    'ahy',\n","    'bukan',\n","    'aniesahy',\n","    'ahmad',\n","    'pks'\n","]\n","\n","def clean_tweet(content):\n","    clean = str(content).lower()\n","    clean = clean.split()\n","    clean = [word for word in clean if not word in keyword]\n","    clean = [word for word in clean if not word in stopwords]\n","    clean = [word for word in clean if not word in double_makna]\n","    clean = [word for word in clean if not word in nama]\n","    clean = ' '.join(clean)\n","    return clean"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["def split(data):\n","    data = str(data)\n","    data = data.split(\" \")\n","    for i in data:\n","        i = i.split(\" \")\n","        if i != 'nan':\n","            split_word.extend(i)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["word_anis_n = pd.DataFrame()\n","word_anis_p = pd.DataFrame()\n","word_prabowo_n = pd.DataFrame()\n","word_prabowo_p = pd.DataFrame()\n","word_ganjar_n = pd.DataFrame()\n","word_ganjar_p = pd.DataFrame()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["split_word = []\n","word_anis_n = df_anis[df_anis['label'] == 'Negative'] \n","word_anis_n = word_anis_n['Clean'].apply(clean_tweet)\n","word_anis_n = word_anis_n.apply(split)\n","split_word = pd.DataFrame(split_word)\n","split_word.dropna(inplace=True)\n","split_word.to_csv('word_cloud/anis/negative.csv')\n","\n","split_word = []\n","word_anis_p = df_anis[df_anis['label'] == 'Positive']\n","word_anis_p = word_anis_p['Clean'].apply(clean_tweet)\n","word_anis_p = word_anis_p.apply(split)\n","split_word = pd.DataFrame(split_word)\n","split_word.dropna(inplace=True)\n","split_word.to_csv('word_cloud/anis/positive.csv')"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["split_word = []\n","word_prabowo_n = df_prabowo[df_prabowo['label'] == 'Negative']\n","word_prabowo_n = word_prabowo_n['Clean'].apply(clean_tweet)\n","word_prabowo_n = word_prabowo_n.apply(split)\n","split_word = pd.DataFrame(split_word)\n","split_word.dropna(inplace=True)\n","split_word.to_csv('word_cloud/prabowo/negative.csv')\n","\n","split_word = []\n","word_prabowo_p = df_prabowo[df_prabowo['label'] == 'Positive']\n","word_prabowo_p = word_prabowo_p['Clean'].apply(clean_tweet)\n","word_prabowo_p = word_prabowo_p.apply(split)\n","split_word = pd.DataFrame(split_word)\n","split_word.dropna(inplace=True)\n","split_word.to_csv('word_cloud/prabowo/positive.csv')"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["split_word = []\n","word_ganjar_n = df_ganjar[df_ganjar['label'] == 'Negative']\n","word_ganjar_n = word_ganjar_n['Clean'].apply(clean_tweet)\n","word_ganjar_n = word_ganjar_n.apply(split)\n","split_word = pd.DataFrame(split_word)\n","split_word.dropna(inplace=True)\n","split_word.to_csv('word_cloud/ganjar/negative.csv')\n","\n","split_word = []\n","word_ganjar_p = df_ganjar[df_ganjar['label'] == 'Positive']\n","word_ganjar_p = word_ganjar_p['Clean'].apply(clean_tweet) \n","word_ganjar_p = word_ganjar_p.apply(split)\n","split_word = pd.DataFrame(split_word)\n","split_word.dropna(inplace=True)\n","split_word.to_csv('word_cloud/ganjar/positive.csv')"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["(398,)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["word_ganjar_n.shape"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["(1484,)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["word_ganjar_p.shape"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["oke.to_csv('oke.csv')"]}],"metadata":{"kernelspec":{"display_name":"bismillah","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
