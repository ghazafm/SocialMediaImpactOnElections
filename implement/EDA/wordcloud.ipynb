{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "anis = pd.read_csv('result/anis.csv')\n",
    "prabowo = pd.read_csv('result/prabowo.csv')\n",
    "ganjar = pd.read_csv('result/ganjar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_meaning = [\n",
    "    'jadi', 'menjadi', 'bapak', 'kalau', 'rakyat', 'siapa', \n",
    "    'apa', 'orang', 'bakal', 'sama', 'pasang', 'jelang', 'tahun', 'hari', \n",
    "    'bersama', 'mau', 'tetap', 'buat', 'for', 'bukan', 'semua', \n",
    "    'terus', 'si', 'inilah', 'kan', 'tak', 'banyak', 'meski', 'lebih', 'keputusan', \n",
    "    'final', 'paling', 'hasil', 'umum', 'tepat', 'tersebut', 'total', 'klik', 'capres', \n",
    "    'pilih', 'pemilihan', 'terpilih', 'survei', 'survey', 'pemilu', 'terkait', 'fahnoor', \n",
    "    'nan', 'calon', 'pilpres', 'resmi', 'cocok', 'politik', 'ribuan', 'ratusan', 'nama','maju',\n",
    "    'hut', 'dapat', 'semoga', 'beliau', 'besar', 'makin', 'layak', 'partai', 'mendukung', 'dukung', \n",
    "    'dukungan', 'gubernur', 'masyarakat', 'warga','presiden','ri','inismyname','pilpres','nan','calon','indonesia','survei','survey','pemilu',\n",
    "    'oligarki','htps','co','t','pak','yg','amp','-','negara','bagai','nya','moga','sat','menang','ubah','amin','republik','pimpin',\n",
    "    'wakil','satu','baik','aamin','bangsa','tuju','semangat','jakarta','lihat','jakarta','sangat','juang','seluruh','insya','doa',\n",
    "    'ayo','enggak','the','benar','siap','beri','bang','milu','wujud','selamat','rawan','kalo','punya','yakin','suara','depan',\n",
    "    'bawa','salam','makmur','bangun','utk','hati','sosok','sehat','gt','video','jangan','insyaalah','aalamin','mas','masa','next',\n",
    "    'memang','harap','kerja','bismilah','nyata','dunia','datang','butuh','baru','kata','atas','selalu','jelas','mampu','alhamdulilah',\n",
    "    'milik','hadir','no','htps','co','t','klo','kau','arti','penuh','yuk','pikir','tambah','kosakata','vs','usai','riak','argentina',\n",
    "    'laga','anakmudaindonesiaemas','aku','februari','hidup','diri','pernah','anak','lama','laku','kali','asli','kamu','sahabatganjar','pasanganbersih',\n",
    "    'indonesiakeren','pranowo-mahfud','ganjarpranowopilihanumat','ganjarmahfudrebound','likeforlikes','ungkap','lsi','jnk',\n",
    "    'desapsi','photography','generasigotongroyong','putih','sebut','sholawat','ribu','menangkanganjar','masing-masing','pemilhan',\n",
    "    'ganjarmenangtotal','tv'\n",
    "    ]\n",
    "name = [\n",
    "    'inismyname', 'indonesia', 'rosiade', 'joko', 'jokowi', 'widodo', 'ridwan', 'kamil', 'rosiade', \n",
    "    'thohir', 'mujani', 'erick', 'saiful', 'chotimah', 'ahy', 'bukan', 'aniesahy', 'ahmad', \n",
    "    'pks', 'pdip', 'jawa', 'puan', 'maharani', 'pan', 'jateng', 'tengah', 'megawati', 'ppp', \n",
    "    'rasyid', 'gerindra', 'nasdem', 'demokrat', 'pkb', 'allah', #maaffff,\n",
    "    'anis', 'anies', 'baswedan', 'prabowo', 'subianto', 'ganjar', 'pranowo','fahnoor', 'amien','sandiaga',\n",
    "    'chotimah', 'uno','alah','muhaimin','iskandar','prabowo-gibran', 'gibran','raka','rakabuming','ganjar-mahfud',\n",
    "    'mahfud','md','ganjarpranowo','ganjarmahfud','pranowo-','pranowomahfud','wahid','anis-muhaimin'\n",
    "\n",
    "]\n",
    "\n",
    "def clean_tweet(content):\n",
    "    clean = str(content).lower()\n",
    "    clean = clean.split()\n",
    "    clean = [word for word in clean if not word in name]\n",
    "    clean = [word for word in clean if not word in double_meaning]\n",
    "    clean = ' '.join(clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    data = str(data)\n",
    "    data = data.split(\" \")\n",
    "    for i in data:\n",
    "        i = i.split(\" \")\n",
    "        split_word.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_anis_n = pd.DataFrame()\n",
    "word_anis_p = pd.DataFrame()\n",
    "word_prabowo_n = pd.DataFrame()\n",
    "word_prabowo_p = pd.DataFrame()\n",
    "word_ganjar_n = pd.DataFrame()\n",
    "word_ganjar_p = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_word = []\n",
    "word_anis_n = anis[anis['sentiment'] == 'Negative'] \n",
    "word_anis_n = word_anis_n['no_stopwords'].apply(clean_tweet)\n",
    "word_anis_n = word_anis_n.apply(split)\n",
    "split_word = pd.DataFrame(split_word)\n",
    "split_word.dropna(inplace=True)\n",
    "word_anis_n = split_word.assign(sentiment='Negative')\n",
    "split_word.to_csv('anis/negative.csv')\n",
    "\n",
    "split_word = []\n",
    "word_anis_p = anis[anis['sentiment'] == 'Positive']\n",
    "word_anis_p = word_anis_p['no_stopwords'].apply(clean_tweet)\n",
    "word_anis_p = word_anis_p.apply(split)\n",
    "split_word = pd.DataFrame(split_word)\n",
    "split_word.dropna(inplace=True)\n",
    "word_anis_n = split_word.assign(sentiment='Positive')\n",
    "split_word.to_csv('anis/positive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_word = []\n",
    "word_prabowo_n = prabowo[prabowo['sentiment'] == 'Negative'] \n",
    "word_prabowo_n = word_prabowo_n['no_stopwords'].apply(clean_tweet)\n",
    "word_prabowo_n = word_prabowo_n.apply(split)\n",
    "split_word = pd.DataFrame(split_word)\n",
    "split_word.dropna(inplace=True)\n",
    "word_prabowo_n = split_word.assign(sentiment='Negative')\n",
    "split_word.to_csv('prabowo/negative.csv')\n",
    "\n",
    "split_word = []\n",
    "word_prabowo_p = prabowo[prabowo['sentiment'] == 'Positive']\n",
    "word_prabowo_p = word_prabowo_p['no_stopwords'].apply(clean_tweet)\n",
    "word_prabowo_p = word_prabowo_p.apply(split)\n",
    "split_word = pd.DataFrame(split_word)\n",
    "split_word.dropna(inplace=True)\n",
    "word_prabowo_n = split_word.assign(sentiment='Positive')\n",
    "split_word.to_csv('prabowo/positive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_word = []\n",
    "word_ganjar_n = ganjar[ganjar['sentiment'] == 'Negative'] \n",
    "word_ganjar_n = word_ganjar_n['no_stopwords'].apply(clean_tweet)\n",
    "word_ganjar_n = word_ganjar_n.apply(split)\n",
    "split_word = pd.DataFrame(split_word)\n",
    "split_word.dropna(inplace=True)\n",
    "word_ganjar_n = split_word.assign(sentiment='Negative')\n",
    "split_word.to_csv('ganjar/negative.csv')\n",
    "\n",
    "split_word = []\n",
    "word_ganjar_p = ganjar[ganjar['sentiment'] == 'Positive']\n",
    "word_ganjar_p = word_ganjar_p['no_stopwords'].apply(clean_tweet)\n",
    "word_ganjar_p = word_ganjar_p.apply(split)\n",
    "split_word = pd.DataFrame(split_word)\n",
    "split_word.dropna(inplace=True)\n",
    "word_ganjar_n = split_word.assign(sentiment='Positive')\n",
    "split_word.to_csv('ganjar/positive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "anis = pd.concat([word_anis_p,word_anis_n])\n",
    "anis = anis.assign(paslon='anies')\n",
    "prabowo = pd.concat([word_prabowo_p,word_prabowo_n])\n",
    "prabowo = prabowo.assign(paslon='prabowo')\n",
    "ganjar = pd.concat([word_ganjar_p,word_ganjar_n])\n",
    "ganjar = ganjar.assign(paslon='ganjar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = pd.concat([anis,prabowo,ganjar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat['word'] = concat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = concat[['word','paslon','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat.to_csv('result/wordcloud.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bismillah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
